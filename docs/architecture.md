# Архитектура модели YOGURT

## Вариант 1
Есть набор предложений, в каждом предложении есть по меньшей мере одно слово, в котором один специальный символ нужно заменить на другой.
Символов в одном слове может быть несколько, слов для замены в предложении тоже. Проблема в том, что менять символ нужно в зависимости от контекста, т. е. от окружающих слов. Правил очень много, формализовать все практически нереально, поэтому смотрю сразу в сторону DL и обучения с учителем на парах предложений до и после замены.

Пока предполагаю, что будут две модели:
 1. Энкодер (уровня слов): кодирует предложение, чтобы отразить в нем связи между словами, семантический смысл и т. п.
 2. Декодер (уровня символов): получает на вход вектор-контекст слов от энкодера и закодированное слово для замены*

Само слово для декодера решил *кодировать вот так:
abcdef (допустим меняем f на z) -> `[2, 0, 0, 0, 0, 0, 1]`, где 2 — позиция слова в тексте, 1 — маркер символа, 0 — паддинг.
На выход от декодера в таком случае жду вектор `[0, 0, 0, 0, 0, 0.75]`, где 0.75 — вероятность (условно) замены f на z.
Поверх этого бинарная кросс-энтропия и классические метрики классификации. Как я это вижу: «менять ли символ f на z».

Для первого приближения к решению пока могу не рассматривать слова, где символов несколько (в большинстве он все же один).
Не исключаю, что я вообще лажу придумал и перемудрил от незнания, поэтому жду, что опытные товарищи укажут на это…

## Вариант 2
_(Ответы в чате)_

Если все правки, которые нужно внести в текст, сводятся к замене символа на символ (без вставки и удаления), то кажется, что `seq2seq` для этой задачи overshoot, и с ней вполне сможет справиться более простая модель формата sequence tagging. Конкретно по архитектуре это может быть и CNN, и RNN, и трансформер, смотря насколько сильна и сложна зависимость от контекста.
Подавал в неё я бы тупо последовательность символов (всё предложение), а на выходе каждого токена требовал бы предсказать распределение над теми символами, которые там на самом деле должны быть.

_— Смущает только, что по факту из всего предложения может быть 1-2 слова для замены, тогда модели придётся на каждый токен выдавать нулевые векторы. Но согласен, по крайней мере это проще и понятнее, чем мои эвристики по кодированию входа._

— Ну и пусть выдает, жалко что ли? Ведь ей же все равно приходится принимать решение, надо ли заменять каждый из этих токенов или нет, так пусть принимает его в явном виде.

_— Кстати правильно же понимаю, что в вашем предложении нельзя готовые эмбеддинги для слов поиспользовать, модель должна сама изучить зависимости между цепочками символов?_

— Если очень хочется, можно в этой модели объединить представления слов и символов: например, на первом слое конкатенировать эмбеддинг символа (обучаемый) с эмбеддингом слова (предобученным).

Но вообще, я не уверен, что при правке текста на уровне символов эмбеддинги слов вообще полезны: во-первых, эмбеддинги слов обычно ничего не знают о написании этих слов (если это не fasttext), а во вторых, при замене символов (чем вы собираетесь заниматься), слово становится другим - и, скорее всего, оно будет OOV для предобученных эмбеддингов.
Впрочем, я могу ошибаться. Можете привести примеры текстов из вашей задачи?

## Полезные ссылки
* [StressRNN](https://github.com/Desklop/StressRNN)
